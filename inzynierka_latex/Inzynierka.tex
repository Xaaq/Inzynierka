\documentclass[12pt]{aghdpl}

\usepackage[english,polish]{babel}

% Użyj polskiego łamania wyrazów (zamiast domyślnego angielskiego).
\usepackage{polski}

\usepackage[utf8]{inputenc}

% dodatkowe pakiety

\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}

% --- < bibliografia > ---

\usepackage[
style=numeric,
sorting=none,
%
% Zastosuj styl wpisu bibliograficznego właściwy językowi publikacji.
language=autobib,
autolang=other,
% Zapisuj datę dostępu do strony WWW w formacie RRRR-MM-DD.
urldate=iso8601,
% Nie dodawaj numerów stron, na których występuje cytowanie.
backref=false,
% Podawaj ISBN.
isbn=true,
% Nie podawaj URL-i, o ile nie jest to konieczne.
url=false,
%
% Ustawienia związane z polskimi normami dla bibliografii.
maxbibnames=3,
% Jeżeli używamy BibTeXa:
backend=bibtex
]{biblatex}

\usepackage{csquotes}
% Ponieważ `csquotes` nie posiada polskiego stylu, można skorzystać z mocno zbliżonego stylu chorwackiego.
\DeclareQuoteAlias{croatian}{polish}

\addbibresource{bibliografia.bib}

% Nie wyświetlaj wybranych pól.
%\AtEveryBibitem{\clearfield{note}}


% ------------------------
% --- < listingi > ---

% Użyj czcionki kroju Courier.
\usepackage{courier}

\usepackage{listings}
\lstloadlanguages{TeX}

\lstset{
	literate={ą}{{\k{a}}}1
           {ć}{{\'c}}1
           {ę}{{\k{e}}}1
           {ó}{{\'o}}1
           {ń}{{\'n}}1
           {ł}{{\l{}}}1
           {ś}{{\'s}}1
           {ź}{{\'z}}1
           {ż}{{\.z}}1
           {Ą}{{\k{A}}}1
           {Ć}{{\'C}}1
           {Ę}{{\k{E}}}1
           {Ó}{{\'O}}1
           {Ń}{{\'N}}1
           {Ł}{{\L{}}}1
           {Ś}{{\'S}}1
           {Ź}{{\'Z}}1
           {Ż}{{\.Z}}1,
	basicstyle=\footnotesize\ttfamily,
}

% ------------------------

\AtBeginDocument{
	\renewcommand{\tablename}{Tabela}
	\renewcommand{\figurename}{Rys.}
}

% ------------------------
% --- < tabele > ---

\usepackage{array}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage[flushleft]{threeparttable}

% defines the X column to use m (\parbox[c]) instead of p (`parbox[t]`)
\newcolumntype{C}[1]{>{\hsize=#1\hsize\centering\arraybackslash}X}


%---------------------------------------------------------------------------

\author{Amadeusz Hercog}
\shortauthor{A. Hercog}

%\titlePL{Przygotowanie bardzo długiej i pasjonującej pracy dyplomowej w~systemie~\LaTeX}
%\titleEN{Preparation of a very long and fascinating bachelor or master thesis in \LaTeX}

\titlePL{Wykorzystanie algorytmu sztucznej inteligencji do rozwiązania problemu optymalnego wyboru ścieżki lub wyjścia ewakuacyjnego}
\titleEN{}


\shorttitlePL{Rozwiązanie problemu optymalnego wyboru ścieżki lub wyjścia ewakuacyjnego} % skrócona wersja tytułu jeśli jest bardzo długi
\shorttitleEN{}

\thesistype{Praca dyplomowa inżynierska}
%\thesistype{Master of Science Thesis}

\supervisor{mgr. inż. Robert Lubaś}
%\supervisor{Marcin Szpyrka PhD, DSc}

\degreeprogramme{Informatyka stosowana}
%\degreeprogramme{Computer Science}

\department{Wydział Informatyki Stosowanej}
%\department{Department of Applied Computer Science}

\faculty{Wydział Fizyki i Informatyki}
%\faculty{Faculty of Electrical Engineering, Automatics, Computer Science and Biomedical Engineering}

\acknowledgements{Serdecznie dziękuję \dots tu ciąg dalszych podziękowań np. dla promotora, żony, sąsiada itp.}

\setlength{\cftsecnumwidth}{10mm}

%---------------------------------------------------------------------------
\setcounter{secnumdepth}{4}
\brokenpenalty=10000\relax

% arial
\renewcommand{\rmdefault}{phv}
\renewcommand{\sfdefault}{phv}

% wyłączenie łamania słów i justowanie
\usepackage[none]{hyphenat}
\sloppy

% wcięcie na pierwszych liniach rozdziałów
\usepackage{indentfirst}

% klikalne linki
\usepackage[colorlinks, linkcolor=blue]{hyperref}

% dane dokumentu
\title{Wykorzystanie algorytmu sztucznej inteligencji do rozwiązania problemu optymalnego wyboru ścieżki lub wyjścia ewakuacyjnego}
\author{Amadeusz Hercog}
\date{21 listopada 2018}

% ładnie wystylizowana tabela
\usepackage[table, svgnames]{xcolor} \usepackage{array}
\usepackage{etoolbox}

\definecolor{table_header_color}{HTML}{B0BEC5}
\definecolor{even_row_color}{HTML}{EEEEEE}

\newenvironment{tightcenter}{
  \setlength\topsep{0pt}
  \setlength\parskip{0pt}
  \begin{center}
}{
  \end{center}
}

\newenvironment{mytabular}{\rowcolors{1}{\ifnumless{\rownum}{2}{table_header_color}{even_row_color}}{}\begin{tightcenter}\tabular}{\endtabular\end{tightcenter}}

%centrowanie nagłówków
\captionsetup{justification=centering}

\begin{document}
	\titlepages
	
	\chapter{Wstęp}
	\textit{W tym rozdziale zostanie opisane podłoże historyczne, cel i jego założenia projektu. Zaprezentowane zostanie proponowane rozwiązanie postawionego problemu oraz technologie do tego użyte.}
	
		\section{Cel projektu}	
		W wielu miastach miastach, gdzie istnieją duże skupiska ludzi prędzej czy później pojawia się problem alokacji przestrzeni na zabudowę. W tym celu nowoczesne budynki uzytku publicznego są projektowane pod kątem wykorzystania jak największej przestrzeni dla celów użytkowych, ale i z drugiej strony - dla zapewnienia jak największego bezpieczeństwa ludziom w nich przebywających. Jednym z czynników określających wchodzącym w skład szeroko pojętego bezpieczeństwa, jest zapewnienie ludziom ścieżek ewakuacyjnych w razie pożaru lub innych wypadków. Z tego powodu celu postawiłem następujący problem - rozwiązanie problemu optymalizacji wyboru ścieżki lub wyjścia ewakuacyjnego ludzi w budynku. Co więcej, w związku z moim wcześniejszym doświadczeniem z tematem uczenia maszynowego, postanowiłem rozwiązać ten problem za pomocą technik machine learning.
		
		\section{Użyte technologie oraz programy}
		Wszystkie obliczenia oraz rysowanie wykresów zostało zrealizowane w języku programowania \textbf{Python} w wersji 3.6 przy użyciu bibliotek:
		\begin{itemize}
			\item \textbf{NumPy} - służąca do obliczeń numerycznych,
			\item \textbf{Pandas} - słuzaca łatwiejszemu zarządzaniu duzą ilością danych,
			\item \textbf{Matplotlib} - służąca do rysowania wykresów,
			\item \textbf{Tensorflow} - używana do głębokiego uczenia maszynowego.
		\end{itemize}
		
		Aby mieć możliwość symulacji ruchu pieszych w budynku, użyłem symulatora \textbf{PSP} \textit{(Pederastian Simulation Project)} autorstwa Roberta Lubaś oraz Wojciecha Myśliwiec - opisany szerzej w rozdziale~\ref{sekcja_psp}.
		
		\section{Proponowane rozwiązanie}
		Rozwiązanie proponowane przeze mnie zostało podzielone na kilka kroków:
		\begin{enumerate}
		\item\label{proponowane_rozwiazanie_generacja_danych} Wygenerowanie \textit{n} zestawów parametrów wejściowych do symulatora \textit{PSP} w celu pozyskania jego danych wyjściowych.
		\item Stworzenie modelu uczenia maszynowego na podstawie wygenerowanych zestawów danych wejściowych oraz wyjściowych symulatora i nauczenie go na danych z punktu~\ref{proponowane_rozwiazanie_generacja_danych}. Daje to możliwość generowania nowych danych wyjściowych bez używania symulatora.
		\item Optymalizacja zestawu danych wyjściowych modelu na podstawie jego danych wejściowych używając metod optymalizacji.
		\end{enumerate}
	
	\newpage
	\chapter{PSP - Pederastian Simulator Project}\label{sekcja_psp}
	\textit{W tym rozdziale opisany zostanie symutalor ruchu pieszych użyty w projekcie i jego sposób użycia wraz z potrzebnymi dodatkowymi plikami. Opisane zostaną użyte w projekcie parametry wejściowe do symulatora oraz metryki stworzone na podstawie jego danych wyjściowych.}
	
		\section{Opis}
		Symulator \textit{Pederastian Simulator Project} jest programem napisanym w języku C++ autorstwa Roberta Lubaś oraz Wojciecha Myśliwiec. Służy on do modelowania ruchu agentów (ludzi) podczas ewakuacji w danej przestrzeni. Symulowana przestrzeń jest dwuwymiarowa, z możliwością dodania wielu poziomów odpowiadających kolejnym piętrom budynku. Główne okno programu jest widoczne na rysunku~\ref{fig: glowne_okno_symulatora}.
	
		\begin{figure}[h]
	 		\begin{tightcenter}
	 			\includegraphics[width = 0.75\linewidth]{rysunki/symulator.png}
	 		\end{tightcenter}
	 		
			\caption{Główne okno symulatora.}
			\label{fig: glowne_okno_symulatora}
		\end{figure}
	
		\section{Sposób użycia}
		Do przeprowadzenia symulacji potrzebne są następujące rzeczy:
		\begin{itemize}
		\item plik \textit{.xml} zawierający parametry wejściowe symulacji,
		\item pliki \textit{.jpg} i \textit{.bmp} zwierające przestrzeń użytą do symulacji.
		\end{itemize}
	
		W oknie głównym programu należy wybrać opcje otwarcia pliku \textit{.xml} po czym od razu zaczyna się symulacja w czasie rzeczywistym. Po symulacji, we wskazanym w pliku z parametrami folderze zostaną wygenerowane pliki \textit{.csv} z danymi wyjściowymi symulacji.
		
		\section{Dane wejściowe i wyjściowe}
		Dane, na których miałem możliwość przeprowadzenia badań znajdowały się w:
		\begin{itemize}
		\item dane wejściowe - plik \textit{.xml},
		\item dane wyjściowe - pliki \textit{.csv}.
		\end{itemize}
		
		Danymi wejściowymi, które wybrałem - na podstawie łatwości modyfikacji - do dalszej analizy były:\label{dane_do_dalszej_analizy}
		
		\begin{itemize}
		\item \textbf{Panic spread factor} - współczynnik, który decyduje jak duzy wpływ ma \textbf{tryb paniki} (tryb, w którym agenci zwracają mniejszą uwagę na otoczenie oraz charakteryzują się bardziej chaotycznym ruchem) na agentów.
		\item \textbf{Panic cancel zone} - współczynnik określający odległość od wyjść, w obrębie jakiej agenci mają szansę na deaktywację trybu paniki.
		\item \textbf{Cancel panic chance}- podczas testów na anulowanie trybu paniki określa procent szans na powodzenie.
		\item \textbf{Choosing evacuation path mode} - tryb wyboru drogi ewakuacyjnej przez agentów. Dostępne są 4 tryby:
			\begin{itemize}
			\item odległości,
			\item gęstości przy wyjściu,
			\item odległości oraz gęstości przy wyjściu,
			\item odległości, gęstości przy wyjściu oraz popularności wyboru wyjścia.
			\end{itemize}
		\item \textbf{Number of pederastians} - liczba agentów biorąca udział w symulacji.
		\item \textbf{Chaos level} - szansa na aktywację trybu paniki u agentów.
		\item \textbf{Density factor} - określa wpływ współczynnika gęstości wokół agenta na funkcję kary.
		\item \textbf{Frequency factor} - określa wpływ częstości wyboru danego pola na funkcję kary.
		\item \textbf{Panic factor} - potęguje część współczynników biorących udział w obliczaniu funkcji kary. 
		\item \textbf{Distance factor} - wpływa na wybór agentów ruchu po skosie lub na wprost.
		\item \textbf{Randomness factor} - czynnik losowości dla wartości kary.
		\item \textbf{Pre-movement time mean value} oraz \textbf{Pre-movement time standard deviation} - średnia i odchylenie czasu \textit{Pre-movement}, który ma wpływ na częstotliwość wykonywania testu na zmianę obranego wyjścia przez agentów.
		\item \textbf{Speed distribution mean value} oraz \textbf{Speed distribution standard deviation} - średnia i odchylenie prędkości agentów.
		\end{itemize}
		
		Dane wyjściowe wybrane wybrane do analizy przeze mnie były następujące:
		
		\begin{itemize}
		\item czas ewakuacji osatatniego agenta (odpowiadający czasowi ewakuacji wszystkich agentów),
		\item błąd średniokwadratowy średnich prędkości wszystkich agentów w stosunku do średniej prędkości najszybszego agenta.
		\end{itemize}
		
		Dodatkowe parametry wejściowe, które były mi potrzebne (lecz nie wpływały na sam proces badawczy) to:
		\begin{itemize}
		\item \textbf{Repeat number} - ilość powtórzeń symulacji wykonanej na pojedynczym pliku \textit{.xml}.
		\item \textbf{Sim directory} - określa ścieżkę do folderu zawierającego pliki symulowanej przestrzeni.
		\item \textbf{Sim stat directory} - określa ścieżkę do folderu, do którego zostaną zapisane dane wyjściowe symulacji (pliki \textit{.csv}).
		\end{itemize}
		
	\newpage
	\chapter{Budowa modelu uczenia maszynowego}
	\textit{W tym rozdziale opisany będzie proces zbierania danych za pomocą symulatora PSP, tworzenie modelu uczenia maszynowego oraz optymalizacji jego wartości wyjściowych.}
	
		\section{Zebranie danych} \label{zebranie_danych}
		W celu zebrania danych, które miałyby trafić później do modelu uczenia maszynowego, stworzyłem skrypt pythonowy, który wygenerował 200 różnych zestawów parametrów wejściowych do symulatora. Rodzaje danych, które wygenerowałem znajdują się w rozdziale~\ref{dane_do_dalszej_analizy}. Dla każdego zestawu danych ustawiłem parametrowi \textit{Repeat number} wartość \textbf{10}, dzięki czemu dla każdego zestawu danych wejściowych generowane było 10 zestawów danych wyjściowych. Było to niezwykle cenne z 2 powodów:
		\begin{itemize}
		\item Do symulatora trzeba było ręcznie ładować plik \textit{.xml}, a dzięki temu z jedngo pliku otrzymywałem od razu 10 zestawów plików wyjściowych.
		\item Ruchy agentów, nawet z takim samym zestawem parametrów, rożnią się między symulacjami, a dzięki powtórzeniom łatwiej było wyeliminować te różnice.
		\end{itemize}
		
		Dla części symulacji, symulator niespodziewanie wyłączył się podczas pracy, przez co niektórym zestawom danych wejściwych odpowiada mniej niż 10 zestawów danych wyjściowych. Ostatecznie z 200 zestawów parametrów wejściowych uzyskałem 1888 zestawów parametrów wyjsciowych. Oznacza to, że 5,6\% z symulacji, które miały zostać przeprowadzone nie udały się.	
		
		W pierwszym podejściu, aby móc przetestować model w prostych warunkach, wybrałem z kazdego zestawu danych: wszystkie dane wejściowe, jedną daną wyjściową. Daną wyjściową, którą wybrałem był czas ewakuacji ostatniego agenta. Każdy zestaw danych zawierał więc \textbf{15} parametrów wejściowych oraz \textbf{1} parametr wyjściowy. Z tak przygotowanymi danymi miałem możliwość wybrania pierwszego modelu.
		
		\section{Opis modelu Perceptron}		
		Na poczatek, wybrałem prosty model uczenia maszynowego - regresję liniową. Stworzyłem go wykorzystując \textbf{Perceptron}. Jest to prosta sieć neuronowa, która posiada zestaw neuronów wejściowych, kazdy odpowiadający pojedynczej danej wejsciowej. Składa się on także z jednego lub wielu niezależnych neuronów wyjściowych. Każdy z nich jest połączony ze wszystkimi neuronami wejściowymi za pomocą krawędzi posiadających wagi - definiują one jak duży wpływ na wyjście ma każda dana wejściowa. Jeśli wyrazimy:
		\begin{itemize}
		\item wejście jako wektor \textit{X},
		\item wyjście pojedyczego Perceptronu jako \textit{a},
		\item neuron jako wektor wag \textit{N},
		\item funkcję aktywacji jako $\sigma$ - jest to funkcja wprowadzająca nieliniowość danych, najpopularniejsze z nich to \textit{Sigmoid}, \textit{ReLU (Rectified linear unit)} czy też \textit{Softmax}
		\end{itemize}
		to zachodzi równanie:
		
		\begin{equation}
		Y=\sigma(NX)
		\end{equation}
	
		Budowa Perceptronu z jednym neuronem wyjściowym jest widoczna na rysunku \ref{fig: budowa_perceptronu}\footnote{\url{https://pythonmachinelearning.pro/perceptrons-the-first-neural-networks/}}.

		\begin{figure}[h]
	 		\begin{tightcenter}
	 			\includegraphics[width = 0.75\linewidth]{rysunki/perceptron.png}
			\end{tightcenter}	 			
	 			
 			\caption{Budowa Perceptronu z jednym neuronem wyjściowym.}
			\label{fig: budowa_perceptronu}
		\end{figure}

		Podczas procesu uczenia \textit{Perceptronu} ważne jest aby określić \textbf{loss function} - metrykę którą chcemy optymalizować. Dla problemów regresji najczęściej uzywaną funkcją kosztu jest \textbf{MSE} (Mean Squared Error). Kolejnym parametrem sieci \textit{Perceptron} jest parametr \textbf{learning rate}, który określa jak bardzo będzie się zmieniać macierz/wektor wag na podstawie gradientu podczas każdej iteracji uczącej. Zbyt duży współczynnik \textit{learning rate} może spowodować, że zamiast optymalizować funkcję kosztu będzie wręcz przeciwnie - będzie ona osiągała coraz większe wartości. Gdy jest on zbyt mały, jest on mniej niebezpieczny gdyż nie doprowadzi on do wzrostu wartości funkcji kosztu; problemem jest jednak wolniejszy proces uczący sieci co wymaga więcej epok uczących. Nie ma jednak uniwersalnej metody regulującej sposób dobierania \textit{learning rate} - trzeba to robić eksperymentalnie.
		
		\section{Pierwszy model - tworzenie i analiza} \label{pierwszy_model_tworzenie_i_analiza}
		Dla powyższych zastosowań stworzyłem więc \textit{Perceptron} posiadający pojdeyncze wyjście oraz nie posiadający funkcji aktywacji - jako że model miał służyć do regresji a nie klasyfikacji. Zestawy danych podzieliłem w stosunku 80\% : 20\% na \textbf{dane treningowe} i \textbf{dane testowe}, pozwala to na trenowanie sieci na danych treningowych oraz sprawdzanie jej efektowności na tanych testowych co daje możliwość walidacji tego, jak dobrze sieć radzi sobie z danymi, z którymi nie miała styczności.
		
		Podsumowując, parametry pierwszego modelu były następujące:
		\begin{itemize}
		\item pojedyncza warstwa składająca się z jednego neuronu,
		\item \textbf{funkcja aktywacji} - brak,
		\item \textbf{learning rate} - 0.1,
		\item \textbf{metryka do optymalizacji} - \textit{MSE},
		\item \textbf{liczba epok uczacych} - 300,
		\item podział na \textbf{dane treningowe} i \textbf{dane testowe} - 80\% : 20\%.
		\end{itemize}
				
		Proces uczący został wykonany 10 razy od nowa na nienauczonym modelu, za kazdym razem wykonując permutację danych. Średnie \textit{MSE} danych wyglądają następująco:
		\begin{itemize}
		\item \textbf{średnie MSE danych treningowych} - 147,77 ($\pm$16,04),
		\item \textbf{średnie MSE danych testowych} - 166,18 ($\pm$50,77).
		\end{itemize}
		Wykres zależności \textit{MSE} danych od iteracji uczacej najlepszego przypadku (biorąc pod uwagę \textit{MSE} danych testowych) jest widoczna na rysunku \ref{fig: pierwszy_model_wykres_uczenia}. Taki rodzaj wykresów będzie nazywany dalej \textbf{wykresami krzywych uczących dla najlepszego przypadku}. Analizując go, doszedłem do następujących wniosków:
		\begin{itemize}
		\item \textit{MSE} danych treningowych jak i testowych jest na wysokim poziomie co oznacza, że model ma \textbf{wysoki bias}. Oznacza to, że użyty model jest zbyt prosty i nie ważne jak dużo danych zostanie do niego podanych i jak długo będzie się on uczył - \textit{MSE} danych nie obniży się poniżej pewnego poziomu.
		\item Podczas uczenia \textit{MSE} danych jest obarczony duzym szumem, co oznacza niestabilność danych lub modelu.
		\item \textit{MSE} danych testowych jest przez większość iteracji mniejsze niż treningowych co oznacza, że dla danych których sieć nie widziała, przewiduje ona wartości bliższe prawdzie niż na danych na których się uczyła. Jest to niecodzienne zachowanie co również dowodzi niestabilności modelu lub danych.
		\end{itemize}
		
		\begin{figure}[h]
	 		\begin{tightcenter}
	 			\includegraphics[width = 0.75\linewidth]{wykresy/1_pierwszy_model_tworzenie_i_analiza/wykres_uczenia.png}
	 		\end{tightcenter}
	 		
 			\caption{Krzywe uczące dla najlepszego przypadku w pierwszym modelu.}
			\label{fig: pierwszy_model_wykres_uczenia}
		\end{figure}
		
		Aby mieć szerszy pogląd na to, jaki wpływ ma ilość danych na których się uczy sieć na \textit{MSE} tych danych - postanowiłem uruchomić proces uczacy kolejne 20 razy dla pojedynczej permutacji danych wejściowych, lecz przy zwiększającej się ilości danych treningowych. Wykres obrazujący wynik tych badań jest widoczny na rysunku \ref{fig: pierwszy_model_learning_curves}. Ten rodzaj wykresów dalej nazywany będzie \textbf{wykresami krzywych uczących dla zmiennej ilości danych}. Informacją jaką można z niego wyciągnąć jest ilość danych potrzebna do tego aby osiągnąć dany pułap \textit{MSE} danych. Widać że podczas gdy przy danych treningowych, większa ich ilość spowodowała spadek ich \textit{MSE} to przy danych testowych nie spowodowało to większej różnicy.
		
		\begin{figure}[h]
	 		\begin{tightcenter}
	 			\includegraphics[width = 0.75\linewidth]{wykresy/1_pierwszy_model_tworzenie_i_analiza/learning_curves.png}
	 		\end{tightcenter}
	 		
 			\caption{Krzywe uczące dla zmiennej ilości danych w pierwszym modelu.}
			\label{fig: pierwszy_model_learning_curves}
		\end{figure}
		
		Podsumowując, obecny model ma wysoki bias - jest zbyt prosty dla danych, przez co większa ich ilość oraz dłuższy proces uczący nie dają żadnych efektów. Na wykresach widać niestabilność modelu lub danych, co powoduje bardzo duże szumy na wykresach \textit{MSE}. Co więcej - niepokojący jest fakt, że \textit{MSE} danych testowych był często niższy niż \textit{MSE} danych treningowych.
		
		\section{Normalizacja danych} \label{normalizacja_danych}
		Mając na uwadze problemy stworzonego modelu, w pierwszej kolejności postanowiłem przejrzeć dane wejściowe do modelu. Ze wszystkich zestawów danych obliczyłem więc średnią każdego z parametrów wejściowych do sieci neuronowej. Wyniki są widoczne w tabeli \ref{srednie_wartosci_i_odchylenia_parametrow_wejsciowych_modelu}. Widać w niej, że niektóre parametry mają wartości 2 rzędy wielkości większe niż inne. Takie różnice pomiędzy różnymi parametrami wejściowymi powodują faworyzowanie przez sieć jednych parametrów ponad drugie. Postanowiłem więc zastosować normalizację danych według wzoru:
		
		\begin{equation}
		X_{new} = \frac{X_{old} - \mu}{\sigma}
		\end{equation}		 
		
		Gdzie:
		\begin{itemize}
		\item $\mu$ - wektor średniej parametrów,
		\item $\sigma$ - wektor odchylenia parametrów.
		\end{itemize}
		
		\begin{table}[t]
			\caption{Średnie wartości parametrów wejściowych do modelu.}
			\begin{mytabular}{r c c}
					\multicolumn{1}{c}{Nazwa parametru} & Średnia wartość \\
					Panic spread factor & 1.74 \\
					Panic cancel zone & 0.53 \\
					Cancel panic chance& 51.59 \\
					Choosing evacuation path mode & 2.53 \\
					Number of pederastian& 271.8 \\
					Chaos level & 53.9 \\
					Density factor & 5.26 \\
					Frequency factor & 5.33 \\
					Panic factor & 1.45 \\
					Distance factor & 2.51 \\
					Randomness factor & 0.49 \\
					Pre-movement time mean value & 5.44 \\
					Pre-movement time standard deviation & 0.51 \\
					Speed distribution mean value & 5.62 \\
					Speed distribution standard deviation & 0.54
			\end{mytabular}
			\label{srednie_wartosci_i_odchylenia_parametrow_wejsciowych_modelu}
		\end{table}
		
		Posiadając tak przygotowane dane wykonałem - tak jak w punkcie \ref{pierwszy_model_tworzenie_i_analiza} - 10 cykli nauczania z różnymi permutacjami danych oraz 20 cykli z jedną permutacją, lecz zmieniającym się rozmiarem zestawu danych treningowych. Średnie \textit{MSE} danych są następujące:
		\begin{itemize}
		\item \textbf{średnia MSE danych treningowych} - 118,64 ($\pm$6,07),
		\item \textbf{średnia MSE danych testowych} - 130,70 ($\pm$23,47).
		\end{itemize}
		Wykres krzywych uczących dla najlepszego przypadku widoczny jest na rysunku \ref{fig: pierwszy_model_wykres_uczenia_z_normalizacja}. Dodatkowo patrząc na wykres krzywych uczących dla zmiennej ilości danych z rysunku \ref{fig: pierwszy_model_learning_curves_z_normalizacja} - widać zależność \textit{MSE} danych od liczby danych treningowych. 
		
		\begin{figure}[h]
			\begin{tightcenter}
	 			\includegraphics[width = 0.75\linewidth]{wykresy/2_normalizacja_danych/wykres_uczenia.png}
	 		\end{tightcenter}
	 		
 			\caption{Krzywe uczące dla najlepszego przypadku w pierwszym modelu ze znormalizowanymi danymi.}
			\label{fig: pierwszy_model_wykres_uczenia_z_normalizacja}
		\end{figure}
		
		\begin{figure}[h]
			\begin{tightcenter}
	 			\includegraphics[width = 0.75\linewidth]{wykresy/2_normalizacja_danych/learning_curves.png}
	 		\end{tightcenter}
	 		
 			\caption{Krzywe uczące dla zmniennej ilości danych w pierwszym modelu ze znormalizowanymi danymi.}
			\label{fig: pierwszy_model_learning_curves_z_normalizacja}
		\end{figure}
		
		Podsumowując, pierwszą rzeczą rzucającą się w oczy jest duża stabilność wartości na wykresach - eliminuje to sytuacje w których wynik uczenia był winą przypadku, jako że kilka iteracji wcześniej lub później \textit{Perceptron} dawał zupełnie inny rezultat. Dzięki większej stabilności sieci łatwiej jest także wyciągać wnioski na podstawie wykresów. Lepiej widoczny jest problem zauważony wcześniej - wysoki bias modelu. Objawia się on tym, że na początku \textit{MSE} danych maleje, aż do pewnego momentu gdzie jest stały i żadna ilość danych albo długość uczenia nie spowoduje jego zmniejszenia. Ostatnią rzeczą, która jest taka sama jak w rozdziale \ref{pierwszy_model_tworzenie_i_analiza} - \textit{MSE} danych testowych często jest mniejsze niż danych treningowych.
		
		\section{Drugi model - tworzenie i analiza} \label{drugi_model_tworzenie_i_analiza}
		Chcąc rozwiązać główny problem poprzedniego modelu - wysoki bias - potrzebowałem modelu, który potrafi nauczyć się bardziej skomplikowanych funkcji. Takim modelem była sieć neuronowa z kilkoma warstwami. Dzięki każdej następnej warstwie ma ona możliwość uczenia się coraz bardziej skomplikowanych funkcji. Sieć jaką stworzyłem miała 1 \textbf{warstwę ukrytą} - warstwę neuronów pomiędzy wejściami a warstwą wyjść - z 30 neuronami. Jako funkcję aktywacji wybrałem funkcję \textit{ReLU}.
		Podsumowując, parametry drugiego modelu były następujące:
		\begin{itemize}
			\item 1 warstwa ukryta z 30 neuronami i funkcją aktywacji ReLU,
			\item warstwa wyjściowa składająca się z jednego neuronu bez funkcji aktywacji,
			\item \textbf{learning rate} - 0.1,
			\item \textbf{metryka do optymalizacji} - MSE,
			\item \textbf{liczba epok uczacych} - 300,
			\item podział na \textbf{dane treningowe} i \textbf{dane testowe} - 80\% : 20\%.
		\end{itemize}
		
		Proces uczący przeprowadziłem identycznie jak poprzednio - wykonałem 10 osobnych cykli uczących z różnymi permutacjami danych oraz 20 osobnych cykli uczących na zmieniającej się wielkości zestawu danych traningowych. Średnie \textit{MSE} danych z 10 cykli są następujące:
		\begin{itemize}
		\item \textbf{średnia MSE danych treningowych} - 47,47 ($\pm$6,08),
		\item \textbf{średnia MSE danych testowych} - 73,66 ($\pm$25,77).
		\end{itemize}
		Wykres krzywych uczacych dla najlepszego przypadku widoczny jest na rysunku \ref{fig: drugi_model_wykres_uczenia} a krzywych uczących dla zmiennej ilości danych - na rysunku \ref{fig: drugi_model_learning_curves}.
		
		\begin{figure}[h]
			\begin{tightcenter}
	 			\includegraphics[width = 0.75\linewidth]{wykresy/3_drugi_model_tworzenie_i_analiza/wykres_uczenia.png}
	 		\end{tightcenter}
	 		
 			\caption{Krzywe uczące dla najlepszego przypadku w drugim modelu.}
			\label{fig: drugi_model_wykres_uczenia}
		\end{figure}
		
		\begin{figure}[h]
			\begin{tightcenter}
	 			\includegraphics[width = 0.75\linewidth]{wykresy/3_drugi_model_tworzenie_i_analiza/learning_curves.png}
	 		\end{tightcenter}
	 		
 			\caption{Krzywe uczące dla zmiennej ilości danych w drugim modelu.}
			\label{fig: drugi_model_learning_curves}
		\end{figure}
		
		Porównując te dane z tymi z sekcji \ref{normalizacja_danych} widać znaczącą poprawę modelu - trzykrotny spadek średnich \textit{MSE} danych treningowych oraz testowych. Mimo tego widać, \textit{MSE} po osiągnięciu pewnego pułapu przestaje maleć - oznacza to, że model dalej ma duży bias.
		
		\section{Zwiększenie stopnia skomplikowania modelu} \label{zwiekszenie_stopnia_skomplikowania_modelu}
		Próbując zmniejszyć bias sieci neuronowej, postanowiłem przeprowadzić eksperymenty z innymi parametrami sieci, a mianowicie:
		\begin{itemize}
		\item liczba warstw ukrytych - \textbf{1}, liczba neuronów w warstwie - \textbf{40};
		\item liczba warstw ukrytych - \textbf{2}, liczba neuronów w każdej warstwie - \textbf{20};
		\item liczba warstw ukrytych - \textbf{2}, liczba neuronów w każdej warstwie - \textbf{40};
		\end{itemize}
		
		Zestawienie wynikow z sekcji \ref{drugi_model_tworzenie_i_analiza} oraz powyższych kombinacji parametrów jest następujące:
		\begin{itemize}
		\item krzywe uczące dla najlepszych przypadków są widoczne na rysunku \ref{fig: drugi_model_kombinacje_parametrow_wykresy_uczenia},
		\item krzywe uczące dla zmiennej ilości danych pokazane są na rysunku \ref{fig: drugi_model_kombinacje_parametrow_learning_curves}.
		\end{itemize}
		
		Dodatkowo średnie \textit{MSE} z 10 różnych permutacji danych zestawiłem w tabeli \ref{srednie_wartosci_mse_dla_roznych_kombinacji_parametrow_sieci}.
		
		\begin{table}[t]
			\caption{Średnie wartości \textit{MSE} danych dla różnych kombinacji parametrów sieci.}
			\begin{mytabular}{c c c c}
					Ilość warstw & Ilość neuronów w warstwie & MSE danych treningowych & MSE danych testowych \\
					1 & 20 & 47,47 ($\pm$6,08) & 73,66 ($\pm$25,77) \\
					1 & 40 & 53,16 ($\pm$4,93) & 47,87 ($\pm$20,13) \\
					2 & 20 & 59,49 ($\pm$10,81) & 89,52 ($\pm$22,04) \\
					2 & 40 & 64,13 ($\pm$7,30) & 70,68 ($\pm$20,42)
			\end{mytabular}
			\label{srednie_wartosci_mse_dla_roznych_kombinacji_parametrow_sieci}
		\end{table}

		\begin{figure}[h]
			\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/3_drugi_model_tworzenie_i_analiza/wykres_uczenia.png}
		 		\caption{1 warstwa ukryta, 20 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/4_zwiekszenie_stopnia_skomplikowania_modelu/1_warstwa_40_neuronow_wykres_uczenia.png}
		 		\caption{1 warstwa ukryta, 40 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/4_zwiekszenie_stopnia_skomplikowania_modelu/2_warstwy_20_neuronow_wykres_uczenia.png}
		 		\caption{2 warstwy ukryte, 20 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/4_zwiekszenie_stopnia_skomplikowania_modelu/2_warstwy_40_neuronow_wykres_uczenia.png}
		 		\caption{2 warstwy ukryte, 40 neuronow w każdej warstwie}
		 	\end{subfigure}
	 	
 			\caption{Krzywe uczące dla najlepszych przypadków przy użyciu różnych kombinacji parametrów w drugim modelu.}
			\label{fig: drugi_model_kombinacje_parametrow_wykresy_uczenia}
		\end{figure}
		
		\begin{figure}[h]
			\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/3_drugi_model_tworzenie_i_analiza/learning_curves.png}
		 		\caption{1 warstwa ukryta, 20 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/4_zwiekszenie_stopnia_skomplikowania_modelu/1_warstwa_40_neuronow_learning_curves.png}
		 		\caption{1 warstwa ukryta, 40 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/4_zwiekszenie_stopnia_skomplikowania_modelu/2_warstwy_20_neuronow_learning_curves.png}
		 		\caption{2 warstwy ukryte, 20 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/4_zwiekszenie_stopnia_skomplikowania_modelu/2_warstwy_40_neuronow_learning_curves.png}
		 		\caption{2 warstwy ukryte, 40 neuronow w każdej warstwie}
		 	\end{subfigure}
	 	
 			\caption{Krzywe uczące dla zmiennej ilosci danych przy różnych kombinacjach parametrów w drugim modelu.}
			\label{fig: drugi_model_kombinacje_parametrow_learning_curves}
		\end{figure}
		
		Mimo zwiększenia stopnia skomplikowania sieci, \textit{MSE} danych treningowych i testowych nie wykazywały tendencji spadkowej. To co powinno się stać w takim przypadku, to \textit{MSE} danych treningowych powinien osiągać coraz niższe wartości wraz ze skomplikowaniem modelu. Na wykresach również widac, że dane testowe miały czasem \textit{MSE} mniejszych od zestawu treningowego. Wnioskiem tej analizy jest to, że problem z uczeniem sieci leży nie w modelu, a w danych.
		
		\section{Uśrednianie danych}
		Wiedząc że problem leży w danych postanowiłem ulepszyć istniejące dane, uśredniając je. W sekcji \ref{zebranie_danych} napisałem, że dla każdego zbioru parametrów wejściowych wygenerowałem do 10 zbiorów parametrów wyjściowych. Dla każdego zestawu wejściowego obliczyłem średnią zestawów parametrów wyjściowych co zmniejszyło ilość danych prawie 10-krotnie. Ostatecznie mój nowy zbiór zawierał 200 zestawów danych (przy czym, podczas procesu uczenia zostały one podzielone na dane treningowe i testowe).
		
		Po przetworzeniu danych postanowiłem powtórzyć badanie z sekcji \ref{zwiekszenie_stopnia_skomplikowania_modelu}, używając kombinacji parametrów:
		\begin{itemize}
		\item ilość warstw ukrytych - \textbf{1} i \textbf{2},
		\item ilość neuronów w każdej warstwie - \textbf{20} i \textbf{40}.
		\end{itemize}
		
		Po powtórzeniu poprzedniego badania na uśrednionych danych, wyniki widać na rysunkach \ref{fig: drugi_model_przy_usrednionych_danych_wykresy_uczenia} i \ref{fig: drugi_model_przy_usrednionych_danych_learning_curves}. Średnie \textit{MSE} danych dla kombinacji parametrów jest umieszczone w tabeli \ref{srednie_wartosci_mse_przy_usrednionych_danych}. 

		\begin{table}[t]
			\caption{Średnie wartości \textit{MSE} danych przy uśrednionych danych.}
			\begin{mytabular}{c c c c}
					Ilość warstw & Ilość neuronów w warstwie & MSE danych treningowych & MSE danych testowych \\
					1 & 20 & 1,38 ($\pm$0,81) & 189,06 ($\pm$60,12) \\
					1 & 40 & 2,21 ($\pm$2,02) & 182,91 ($\pm$50,58) \\
					2 & 20 & 6,06 ($\pm$8,93) & 113,56 ($\pm$55,77) \\
					2 & 40 & 2,02 ($\pm$4,38) & 108,03 ($\pm$40,39)
			\end{mytabular}
			\label{srednie_wartosci_mse_przy_usrednionych_danych}
		\end{table}

		\begin{figure}[h]
			\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/5_usrednianie_danych/1_warstwa_20_neuronow_wykres_uczenia.png}
		 		\caption{1 warstwa ukryta, 20 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/5_usrednianie_danych/1_warstwa_40_neuronow_wykres_uczenia.png}
		 		\caption{1 warstwa ukryta, 40 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/5_usrednianie_danych/2_warstwy_20_neuronow_wykres_uczenia.png}
		 		\caption{2 warstwy ukryte, 20 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/5_usrednianie_danych/2_warstwy_40_neuronow_wykres_uczenia.png}
		 		\caption{2 warstwy ukryte, 40 neuronow w każdej warstwie}
		 	\end{subfigure}
	 	
 			\caption{Krzywe uczące dla najlepszych przypadków przy uśrednionych danych w drugim modelu.}
			\label{fig: drugi_model_przy_usrednionych_danych_wykresy_uczenia}
		\end{figure}
		
		\begin{figure}[h]
			\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/5_usrednianie_danych/1_warstwa_20_neuronow_learning_curves.png}
		 		\caption{1 warstwa ukryta, 20 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/5_usrednianie_danych/1_warstwa_40_neuronow_learning_curves.png}
		 		\caption{1 warstwa ukryta, 40 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/5_usrednianie_danych/2_warstwy_20_neuronow_learning_curves.png}
		 		\caption{2 warstwy ukryte, 20 neuronow w każdej warstwie}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/5_usrednianie_danych/2_warstwy_40_neuronow_learning_curves.png}
		 		\caption{2 warstwy ukryte, 40 neuronow w każdej warstwie}
		 	\end{subfigure}
	 	
 			\caption{Krzywe uczące dla zmniennej ilości uśrednionych danych w drugim modelu.}
			\label{fig: drugi_model_przy_usrednionych_danych_learning_curves}
		\end{figure}
		
		Analizując dane, można zauważyć że po uśrednieniu zachowują się one zgodnie z przewidywaniami - większe skomplikowanie sieci neuronowej zmniejszyło dramatycznie \textit{MSE} danych treningowych. Co było również spodziewane - \textit{MSE} danych testowych pozostał wysoki; jednakże na wykresach \ref{fig: drugi_model_przy_usrednionych_danych_learning_curves} (c) i (d) widać ciekawą tendencję - wygląda na to, że przy większych rozmiarach zbioru danych nawet \textit{MSE} zbioru testowego zaczyna się obniżać. Podobną tendencję, lecz słabszą można też zauwazyć na wykresach \ref{fig: drugi_model_przy_usrednionych_danych_learning_curves} (a) i (b) po przekroczeniu pułapu 140 zestawów danych uczących. Gdy model jest zbyt dobrze przyuczony do danych treningowych i źle generalizuje na danych testowych, mówi się że posiada on \textbf{wysoką wariancję}.
		
		Ze względu na duży czas oczekiwania oraz potrzebę ciągłego nadzoru nad symulatorem, postanowiłem w pirewszej kolejności poszukać innych sposobów na zwiększenie efektowności modelu.
		
		\section{Regularyzacja modelu}
		Chcąc obnizyć wariancję modelu uczenia maszynowego stosuje się techniki zwane regularyzacją. Najprostsze z nich czyli regularyzacja \textbf{L1} i \textbf{L2} polegają na dodaniu współczynnika kary do funkcji kosztu. Karze ona model za posiadanie wysokich wag na połączeniach pomiędzy neuronami. Dla porównania mając funkcję kosztu \ref{loss_function}, używając regularyzacji \textit{L1} będzie ona wyglądać jak na równaniu \ref{loss_function_l1} a regularyzacji \textit{L2} - tak jak na równaniu \ref{loss_function_l2}. Współczynnik $\lambda$ to tak zwany \textbf{współczynnik regularyzacji} - odpowiada on za siłę, z jaką wagi będa zmniejszane.
		
		\begin{equation} \label{loss_function}
		S = \sum_{i = 1}^n (y_i - f(x_i))^2
		\end{equation}
		\begin{equation} \label{loss_function_l1}
		S = \sum_{i = 1}^n (y_i - f(x_i))^2 + \lambda \sum_{i = 1}^k |w_i|
		\end{equation}
		\begin{equation} \label{loss_function_l2}
		S = \sum_{i = 1}^n (y_i - f(x_i))^2 + \lambda \sum_{i = 1}^k w_i^2
		\end{equation}
		
		Bazując na badaniach z poprzedniego rozdziału, wybrałem model z jedną 20-neuronową warstwą ukrytą aby przeprowadzić na nim eksperymenty z regularyzacją. Mój wybór był umotywowany tym, że był to najprostszy z 4 modeli, a jednocześnie miał możliwość prawie idealnego nauczenia się danych treningowych. Parametry regularyzacji jakie wybrałem do badań to:
		\begin{itemize}
		\item funkcje regularyzujące - \textbf{L1} i \textbf{L2},
		\item parametr regularyzacji $\lambda$ - \textbf{0,1}; \textbf{0,3}; \textbf{1}; \textbf{3}.
		\end{itemize}
		
		\begin{table}[t]
			\caption{Średnie wartości \textit{MSE} danych przy regularyzacji.}
			\begin{mytabular}{c c c c}
					Rodzaj regularyzacji & Ilość neuronów w warstwie & MSE danych treningowych & MSE danych testowych \\
					L1 & 0.1 & 11,65 ($\pm$15,70) & 99,61 ($\pm$43,27) \\
					L1 & 0.3 & 7,68 ($\pm$1,04) & 82,24 ($\pm$39,32) \\
					L1 & 1 & 15,89 ($\pm$3,44) & 36,21 ($\pm$24,35) \\
					L1 & 3 & 40,44 ($\pm$21,46) & 64,26 ($\pm$39,62) \\
					L2 & 0.1 & 7,42 ($\pm$1,74) & 102,93 ($\pm$47,46) \\
					L2 & 0.3 & 20,04 ($\pm$3,16) & 76,49 ($\pm$36,76) \\
					L2 & 1 & 53,44 ($\pm$4,77) & 81,18 ($\pm$43,06) \\
					L2 & 3 & 103,04 ($\pm$7,29) & 62,86 ($\pm$34,93)
			\end{mytabular}
			\label{srednie_wartosci_mse_przy_regularyzacji}
		\end{table}

		\begin{figure}[h]
			\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l1/regularyzacja_0_1_wykres_uczenia.png}
		 		\caption{parametr $\lambda$ - 0.1}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l1/regularyzacja_0_3_wykres_uczenia.png}
		 		\caption{parametr $\lambda$ - 0.3}
		 	\end{subfigure}
		 	
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l1/regularyzacja_1_wykres_uczenia.png}
		 		\caption{parametr $\lambda$ - 1}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l1/regularyzacja_3_wykres_uczenia.png}
		 		\caption{parametr $\lambda$ - 3}
		 	\end{subfigure}
		  	
		  	\caption{Krzywe uczące dla najlepszych przypadków używając regularyzacji L1 w drugim modelu.}
			\label{fig: drugi_model_przy_regularyzacji_l1_wykresy_uczenia}
		\end{figure}
		 	
		 \begin{figure}[h]
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l2/regularyzacja_0_1_wykres_uczenia.png}
		 		\caption{parametr $\lambda$ - 0.1}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l2/regularyzacja_0_3_wykres_uczenia.png}
		 		\caption{parametr $\lambda$ - 0.3}
		 	\end{subfigure}
		 	
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l2/regularyzacja_1_wykres_uczenia.png}
		 		\caption{parametr $\lambda$ - 1}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l2/regularyzacja_3_wykres_uczenia.png}
		 		\caption{parametr $\lambda$ - 3}
		 	\end{subfigure}
	 	
 			\caption{Krzywe uczące dla najlepszych przypadków używając regularyzacji L2 w drugim modelu.}
			\label{fig: drugi_model_przy_regularyzacji_l2_wykresy_uczenia}
		\end{figure}
		
		\begin{figure}[h]
			\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l1/regularyzacja_0_1_learning_curves.png}
		 		\caption{parametr $\lambda$ - 0.1}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l1/regularyzacja_0_3_learning_curves.png}
		 		\caption{parametr $\lambda$ - 0.3}
		 	\end{subfigure}
		 	
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l1/regularyzacja_1_learning_curves.png}
		 		\caption{parametr $\lambda$ - 1}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l1/regularyzacja_3_learning_curves.png}
		 		\caption{parametr $\lambda$ - 3}
		 	\end{subfigure}
		  	
		  	\caption{Krzywe uczące dla zmiennej ilości danych używając regularyzacji L1 w drugim modelu.}
			\label{fig: drugi_model_przy_regularyzacji_l1_learning_curves}
		\end{figure}
		 	
		 \begin{figure}[h]
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l2/regularyzacja_0_1_learning_curves.png}
		 		\caption{parametr $\lambda$ - 0.1}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l2/regularyzacja_0_3_learning_curves.png}
		 		\caption{parametr $\lambda$ - 0.3}
		 	\end{subfigure}
		 	
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l2/regularyzacja_1_learning_curves.png}
		 		\caption{parametr $\lambda$ - 1}
		 	\end{subfigure}
		 	\begin{subfigure}{.5\linewidth}
		 		\includegraphics[width =\linewidth]{wykresy/6_regularyzacja/l2/regularyzacja_3_learning_curves.png}
		 		\caption{parametr $\lambda$ - 3}
		 	\end{subfigure}
	 	
 			\caption{Krzywe uczące dla zmiennej ilości danych używając regularyzacji L2 w drugim modelu.}
			\label{fig: drugi_model_przy_regularyzacji_l2_learning_curves}
		\end{figure}
		
		\printbibliography
\end{document}
